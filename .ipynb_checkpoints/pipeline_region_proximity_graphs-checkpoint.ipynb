{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b23a85-3612-47b3-b68b-f3bb846c23e2",
   "metadata": {},
   "source": [
    "# Whole skeleton neuron df queying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abbc1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuprint import fetch_synapses, NeuronCriteria as NC, SynapseCriteria as SC\n",
    "from neuprint import Client\n",
    "from neuprint import fetch_adjacencies, NeuronCriteria as NC\n",
    "from neuprint import fetch_neurons\n",
    "from neuprint import merge_neuron_properties\n",
    "from neuprint import fetch_roi_hierarchy\n",
    "import math\n",
    "import json\n",
    "from neuprint import fetch_synapse_connections\n",
    "from neuprint import Client\n",
    "from urllib.error import URLError, HTTPError\n",
    "from urllib.request import urlopen\n",
    "import timeit\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "import pickle\n",
    "from scipy.spatial import KDTree\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c9d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6Imx1a2FibGFnb2pldmljMTk5NUBnbWFpbC5jb20iLCJsZXZlbCI6Im5vYXV0aCIsImltYWdlLXVybCI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hLS9BT2gxNEdqdDZpdFFGR2xTSWZUTElNTjRmcEt1QzZ3QmE2Rlp0WU1XYmpKV1ZBPXM5Ni1jP3N6PTUwP3N6PTUwIiwiZXhwIjoxODA5MTE1OTEyfQ.0h6CJp8xfQEpkW8a2_gqJUBrEA5GyBiZkNvDjRpoXoY\" # <--- Paste your token here\n",
    "           # (This is my personal token)\n",
    "\n",
    "c = Client('neuprint.janelia.org', 'hemibrain:v1.2.1', TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96fa6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hemibrain': {'AL(L)*': {}, 'AL(R)*': {}, 'AOT(R)': {}, 'CX': {'AB(L)*': {}, 'AB(R)*': {}, 'EB*': {}, 'FB*': {}, 'NO*': {}, 'PB*': {}}, 'GC': {}, 'GF(R)': {}, 'GNG*': {}, 'INP': {'ATL(L)*': {}, 'ATL(R)*': {}, 'CRE(L)*': {}, 'CRE(R)*': {}, 'IB*': {}, 'ICL(L)*': {}, 'ICL(R)*': {}, 'SCL(L)*': {}, 'SCL(R)*': {}}, 'LH(R)*': {}, 'LX(L)': {'BU(L)*': {}, 'LAL(L)*': {}}, 'LX(R)': {'BU(R)*': {}, 'LAL(R)*': {}}, 'MB(+ACA)(R)': {'MB(R)': {'CA(R)*': {}, 'PED(R)*': {}, \"a'L(R)*\": {}, 'aL(R)*': {}, \"b'L(R)*\": {}, 'bL(R)*': {}, 'gL(R)*': {}}, 'dACA(R)': {}, 'lACA(R)': {}, 'vACA(R)': {}}, 'MB(L)': {'CA(L)*': {}, \"a'L(L)*\": {}, 'aL(L)*': {}, \"b'L(L)*\": {}, 'bL(L)*': {}, 'gL(L)*': {}}, 'OL(R)': {'AME(R)*': {}, 'LO(R)*': {}, 'LOP(R)*': {}, 'ME(R)*': {}}, 'PENP': {'CAN(R)*': {}, 'FLA(R)*': {}, 'PRW*': {}, 'SAD*': {}}, 'POC': {}, 'SNP(L)': {'SIP(L)*': {}, 'SMP(L)*': {}}, 'SNP(R)': {'SIP(R)*': {}, 'SLP(R)*': {}, 'SMP(R)*': {}}, 'VLNP(R)': {'AOTU(R)*': {}, 'AVLP(R)*': {}, 'PLP(R)*': {}, 'PVLP(R)*': {}, 'WED(R)*': {}}, 'VMNP': {'EPA(L)*': {}, 'EPA(R)*': {}, 'GOR(L)*': {}, 'GOR(R)*': {}, 'IPS(R)*': {}, 'SPS(L)*': {}, 'SPS(R)*': {}, 'VES(L)*': {}, 'VES(R)*': {}}, 'mALT(L)': {}, 'mALT(R)': {}}}\n"
     ]
    }
   ],
   "source": [
    "# Show the ROI hierarchy, with primary ROIs marked with '*'\n",
    "print(fetch_roi_hierarchy(False, format='dict'))\n",
    "roi_dict = fetch_roi_hierarchy(False, format='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92532da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_list = list(roi_dict['hemibrain']['OL(R)'].keys())[-1:]\n",
    "roi_list = ['ME(R)*','EPA(L)*',\n",
    " 'EPA(R)*',\n",
    " 'GOR(L)*',\n",
    " 'GOR(R)*',\n",
    " 'IPS(R)*',\n",
    " 'SPS(L)*',\n",
    " 'SPS(R)*',\n",
    " 'VES(L)*',\n",
    " 'VES(R)*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lengths = {}\n",
    "neuron_df_dict = {}\n",
    "for key in roi_list:\n",
    "    if key[-1:] == '*':\n",
    "        key = key[:-1]\n",
    "    else:\n",
    "        key = key\n",
    "    criteria = NC(min_roi_inputs=0,min_roi_outputs=0, inputRois=[key], outputRois=[key])\n",
    "    neuron_df, roi_counts_df = fetch_neurons(criteria)\n",
    "    dataset_lengths[key] = len(neuron_df)\n",
    "    neuron_df.to_csv('neuron_regions_neuron_df/' + key+'_'+str(len(neuron_df)) + '.csv')\n",
    "    neuron_df_dict[key] = neuron_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9749c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons in selected datasets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ME(R)': 3721,\n",
       " 'EPA(L)': 1174,\n",
       " 'EPA(R)': 1465,\n",
       " 'GOR(L)': 1221,\n",
       " 'GOR(R)': 1230,\n",
       " 'IPS(R)': 2799,\n",
       " 'SPS(L)': 5017,\n",
       " 'SPS(R)': 5273,\n",
       " 'VES(L)': 2182,\n",
       " 'VES(R)': 3722}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of neurons in selected datasets')\n",
    "dataset_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['pt_id','x','y','z','radius','bodyId']\n",
    "df_dict = {}\n",
    "skeleton_df = pd.DataFrame(columns=columns)\n",
    "for neuron_df_key in neuron_df_dict.keys():\n",
    "    print(neuron_df_key)\n",
    "    neuron_df = neuron_df_dict[neuron_df_key]\n",
    "    for bodyId in neuron_df['bodyId'].to_list():\n",
    "        try:\n",
    "            s =  c.fetch_skeleton(body = int(bodyId),format='pandas')\n",
    "            s['bodyId'] = str(bodyId)\n",
    "            s['pt_id'] = s['bodyId'] + '_' + s['rowId'].astype('str')\n",
    "            skeleton_df = pd.concat([skeleton_df,s])\n",
    "            count += 1\n",
    "            count_save +=1\n",
    "        except:\n",
    "            if 1 == 0:\n",
    "             print(\"Neuron was not loaded\")\n",
    "    #skeleton_df = skeleton_df[['pt_id','x','y','z','radius','bodyId']]\n",
    "    skeleton_df = skeleton_df[['pt_id','rowId','x','y','z','link','radius','bodyId']]\n",
    "    skeleton_df.to_csv('neuron_regions_points/' + neuron_df_key+'_'+str(len(neuron_df)) + '.csv')\n",
    "    df_dict[neuron_df_key] = skeleton_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_df.to_csv('neuron_regions_points/' + neuron_df_key+'_'+str(len(neuron_df)) + '.csv')\n",
    "    df_dict[neuron_df_key] = skeleton_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe80e6e",
   "metadata": {},
   "source": [
    "# Radius distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f71154",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_df.to_csv('neuron_regions_points/' + neuron_df_key+'_'+str(len(neuron_df)) + '.csv')\n",
    "    df_dict[neuron_df_key] = skeleton_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df_dict = {}\n",
    "for region_key in df_dict.keys():\n",
    "    points_df = df_dict[region_key]\n",
    "    points_df_dict[region_key] = points_df[['x','y','z','radius','bodyId']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(np.median(points_numpy[:,3])/2)\n",
    "for region_key in points_df_dict:\n",
    "    print(\"Mean radius\")\n",
    "    print(np.mean(points_df_dict[region_key]['radius']))\n",
    "    print('Mean std')\n",
    "    print(np.std(points_df_dict[region_key]['radius']))\n",
    "    plt.hist(points_df_dict[region_key]['radius'],bins=200,label=str(region_key));\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Segment radius')\n",
    "    plt.legend()\n",
    "    #plt.title('Segment radius distribution - 3000 neurons dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac5757-fe30-4863-a5c0-b3ab9a91b0ac",
   "metadata": {},
   "source": [
    "# Using k-d trees to create proximity graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a single row with 3D coordinates local radius/diameter and bodyid. Returns 14 points around it, without radius.\n",
    "def spherical_sample_dataframe_row(array):\n",
    "        results_array = np.empty((0,4),np.float64)\n",
    "        point = np.array([array[0],array[1],array[2],array[4]])\n",
    "        #if diameter_or_radius == \"diameter\":\n",
    "        # If input is diameter, divide by 2 to get radius\n",
    "        r = array[3]\n",
    "        #elif diameter_or_radius == \"radius\":\n",
    "        #    r = array[3]\n",
    "        points_array = [point + np.array([0,0,r,0]),point + np.array([0,0,-r,0]),point + np.array([0,r,0,0]),point + np.array([0,-r,0,0]),\n",
    "                        point + np.array([r,0,0,0]),point + np.array([-r,0,0,0]),point + np.array([r * 1/2,r * 1/2,r* np.sqrt(2)/2,0]),point + np.array([r * 1/2,-r* 1/2,r* np.sqrt(2)/2,0]),\n",
    "                        point + np.array([-r* 1/2,r* 1/2,r* np.sqrt(2)/2,0]),point + np.array([-r* 1/2,-r* 1/2,r* np.sqrt(2)/2,0]),point + np.array([r* 1/2,r *1/2,-r* np.sqrt(2)/2,0]),\n",
    "                        point + np.array([r* 1/2,-r* 1/2,-r* np.sqrt(2)/2,0]), point + np.array([-r* 1/2,r* 1/2,-r* np.sqrt(2)/2,0]),point + np.array([-r* 1/2,-r* 1/2,-r* np.sqrt(2)/2,0])\n",
    "                                    ]\n",
    "        results_array =   np.append(results_array,np.array(points_array),axis=0)\n",
    "        return np.array(results_array).astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f97032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_bodyid_kd_tree(points_df,spherical):\n",
    "    start_total = timeit.default_timer()\n",
    "    if spherical == True:\n",
    "        points_numpy = points_df.to_numpy()\n",
    "        points_numpy = np.apply_along_axis(spherical_sample_dataframe_row,1,points_numpy )\n",
    "        points_numpy = np.concatenate(points_numpy)\n",
    "    else:\n",
    "        points_df_non_spherical = points_df[['x','y','z','bodyId']]\n",
    "        points_numpy = points_df_non_spherical.to_numpy()\n",
    "    end_total = timeit.default_timer()\n",
    "    print('Loading time:',end_total-start_total)\n",
    "    body_id_array, occurence_start_array = np.unique(points_numpy[:,3],return_index = True)\n",
    "    occurence_start_array = np.sort(occurence_start_array)\n",
    "    big_tree = KDTree(points_numpy[:,:3],compact_nodes=True,balanced_tree=True,leafsize = 400)\n",
    "    end_total = timeit.default_timer()\n",
    "    print('KD Tree construction time:',end_total-start_total)\n",
    "    return big_tree,body_id_array,occurence_start_array,points_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e02baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tree_with_neuron_bodyid(big_tree,occurence_start_array,body_id_array,points_numpy,radius):\n",
    "    metagraph_edgelist_dictionary = {}\n",
    "    for i in range(0,occurence_start_array.shape[0]):\n",
    "            body_id = int(points_numpy[:,3][occurence_start_array[i]])\n",
    "            if i <occurence_start_array.shape[0]-1:\n",
    "                interval_start_index = occurence_start_array[i]\n",
    "                interval_end_index = occurence_start_array[i+1]\n",
    "                results = big_tree.query_ball_point(points_numpy[interval_start_index :interval_end_index, :3], r = radius,return_sorted=True)\n",
    "                results_array = np.fromiter(itertools.chain.from_iterable(results), np.int64)\n",
    "            else:\n",
    "                interval_start_index = occurence_start_array[i]\n",
    "                results = big_tree.query_ball_point(points_numpy[interval_start_index :, :3], r = radius,return_sorted=True)\n",
    "                results_array = np.fromiter(itertools.chain.from_iterable(results), np.int64)\n",
    "            unique_results = np.unique(results_array)\n",
    "            metagraph_edgelist_dictionary[body_id] = []\n",
    "            # Check for each neuron if it's in the neighborhood\n",
    "            for j in range(0,occurence_start_array.shape[0]):\n",
    "                    # Remove the neuron we are looking at \n",
    "                    body_id_neighbor =  int(points_numpy[:,3][occurence_start_array[j]])\n",
    "                    if body_id != body_id_neighbor:\n",
    "                        if j <occurence_start_array.shape[0]-1:\n",
    "                            interval_start_index = occurence_start_array[j]\n",
    "                            interval_end_index = occurence_start_array[j+1]\n",
    "                            #print('BodyID of the testing neighbor neuron:',body_id_neighbor)\n",
    "                            #print('Starting index of the neuron in the large array:',interval_start_index)\n",
    "                            #print('Ending index of the neuron in the large array:',interval_end_index)\n",
    "                            mask_inverted = np.logical_and((interval_start_index  <= unique_results),(unique_results < interval_end_index))\n",
    "                        else:\n",
    "                            interval_start_index = occurence_start_array[-1]\n",
    "                            #print('BodyID of the testing neighbor neuron:',body_id_neighbor)\n",
    "                            #print('Starting index of the neuron in the large array:',interval_start_index)\n",
    "                            #print('Ending index of the neuron in the large array:',)\n",
    "                            mask_inverted = np.logical_and((interval_start_index  <= unique_results),True)\n",
    "                        statement = mask_inverted.any()\n",
    "                        #If the neighbor with this bodyid is present in the neighborhood\n",
    "                        if mask_inverted.any():\n",
    "                            metagraph_edgelist_dictionary[body_id].append(body_id_neighbor)\n",
    "                        mask = np.logical_not(mask_inverted) \n",
    "                        unique_results = unique_results[mask]\n",
    "                        if unique_results.size == 0: #If array is emptied, stop the process\n",
    "                            break\n",
    "    return metagraph_edgelist_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16212395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for region_key in list(points_df_dict.keys()):\n",
    "    print(region_key)\n",
    "    spherical = True\n",
    "    points_df = points_df_dict[region_key]\n",
    "    big_tree,body_id_array,occurence_start_array,points_numpy = dataframe_to_bodyid_kd_tree(points_df,spherical)\n",
    "    total_number_of_edges_spherical = []\n",
    "    radius_list_spherical = [0, 1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 45, 50, 60, 70, 80, 90, 100, 150, 200]#, 250, 300, 350, 450, 500]\n",
    "    for radius in radius_list_spherical:\n",
    "        start_total = timeit.default_timer()\n",
    "        metagraph_edgelist_dictionary = {}\n",
    "        print('Radius',radius)\n",
    "        metagraph_edgelist_dictionary = query_tree_with_neuron_bodyid(big_tree,occurence_start_array,body_id_array,points_numpy,radius)\n",
    "        count_edges = 0\n",
    "        # Go through each neuron and count the number of it's neighbors\n",
    "        for key in metagraph_edgelist_dictionary.keys():\n",
    "            count_edges += len(metagraph_edgelist_dictionary[key])\n",
    "        # Edges are always double counted, since i - j will always have j-i as a neighbor\n",
    "        count_edges = count_edges/2\n",
    "        total_number_of_edges_spherical.append(count_edges)\n",
    "        end_total = timeit.default_timer()\n",
    "        print('Total time taken for radius:',end_total-start_total)\n",
    "        print('Count',count_edges)\n",
    "        with open(region_key+\"_edge_dict_spherical_\" + str(radius)+\".pkl\", \"wb\") as h:\n",
    "                    pickle.dump(metagraph_edgelist_dictionary, h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004040b9",
   "metadata": {},
   "source": [
    "Result files are stored in pickle as dictionaries, which show neighbors at a certain threshold distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffd168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
